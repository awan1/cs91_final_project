\section{Project Proposal}

\subsection{Problem}
\textbf{A description of the problem you plan to solve and the motivations for doing so (i.e., why this problem is interesting/important).}

Twitter is a social media platform with 284 million users active per month, tweeting approximately 500 million tweets
per day.~\cite{twitter} At a maximum of 140 characters per tweet and about 1 byte per character\footnote{Issues arise with different
encodings, but we ignore these for the sake of our back-of-the-envelope calculation} this represents an informational
flow of over 70GB of text per day. An average book is about 2MB in size~\cite{bookfact}, so Twitter users are collectively
writing about 35,000 books a day.

With this wealth of textual information that is often supplemented with geo-location data and content-connecting hashtags,
it is no surprise that a multitude of tools have arisen to harvest the information encoded in tweets. Twitter's
API~\cite{twitterAPI} has been used to build visualizations of tweet locations and several third party apps
have been created: Tweet Ping is a website that tracks live tweets and displays them like lights on a global map~\cite{tweetping1}
~\cite{tweetping2}; A World of Tweets is a similar website that builds a heatmap of tweets~\cite{worldoftweets}; Tweet Beam
creates a wall of tweets based on a given hashtag or search query~\cite{tweetbeam}. These are just a few of the many apps that
utilize the live stream of tweets from Twitter.

Existing products that leverage the informational wealth of Twitter are mostly interested in geolocation, and are either
purely historical or purely live. Few, if any, current products focus on the connection between tweets or go in anyway go beyond
simply using geolocation or maybe a keyword. We seek to move away from this problem space by creating a product that:
\begin{itemize}[noitemsep]
\item Uses both historical and live-stream data
\item Focuses on relationships between tweets, users, and content, rather than on just their location
\item Displays these relationships in a visually pleasing way
\end{itemize}



\subsection{Goals}
\textbf{The goals you have for the project. What constitutes success and how will you evaluate it?}

Our goal for this project is to have a fully functional visualization depicting the popularity of tweets (based on
re-tweets) and the connectivity of tweets being currently tweeted (based on @replies and hashtags). We will also keep a
small (several week long) history of tweets, so that users have the option of viewing a graph of historical tweets as
well as a new graph of tweets starting from when the program is initialized.

The primary goal of this project is to create a (relatively) novel visualization of relationships between Twitter users.
As such, success can be measured by the quality of the insights that \sys provides. By exploring the visualizations 
produced and seeing what interesting (see \S \ref{sec:hypothesis} for an articulation of the trends that we hope to see),
we would consider the quality of the insights gleaned from \sys a marker for its success.

Equally central to this project is how we can present interesting information in aesthetically pleasing, intuitive ways.
New information is no benefit if it does not elucidate the data that it is gleaned from. To have value, visualizations
must be pleasing to the eye and easy on the mind. 

Thus, our goals can be summarized as follows: we wish to create a product that
\begin{itemize}[noitemsep]
\item Provides interesting insights into the culture of Twitter by mapping interactions of users
\item Displays both historical and live-stream data
\item Presents an aesthetically pleasing, intuitive way to understand Twitter from a different, global perspective.
\end{itemize}

We envision \sys working as follows: users access a webpage which starts blank and immediately starts populating with
live tweets. The tweets grow in size as they are retweeted, tweets that are replies are connected, and tweets are 
clustered by conversation rather than by location. Coloring could be used based on mood --- a plug-in affect detection
module could be an interesting demonstration of the modularity of our work. The window changes in size to accomodate the
largest (most retweeted) tweets. Users can move the window around by dragging and clicking, and can zoom in and out
by scrolling. Tweets contain a user handle and/or (user-provided) real name, a snippet of content, and can be clicked on
to access the full tweet. (see Listen to Wikipedia for inspiration?)

\subsection{Hypothesis} \label{sec:hypothesis}
\textbf{Your hypothesis: given the work you intend to do, what are the results you expect to see? How does this work help to solve the problem?}

Through this work, we expect to be able to provide a different type of Twitter visualization than what is currently available.
We expect to be able to generate graphs that allow us to "watch" different Twitter conversations happen in real time. While
we won't be able to see specific tweets, we will be able to see the topics of conversations (based on hashtags) as well as
what high-profile accounts are taking part in the conversation in real-time.

The main difference between our visualization of Twitter data and currently existing visualization tools is that we choose
to focus on the connectivity and topics of tweets rather than on location information. Current Twitter visualization tools
allow users to see where and when people are tweeting. This take on visualization, while cool, may not actually provide
any new information about the Twittersphere. Location data for tweets correlates closely with population distribution data (i.e.
major cities have a lot of people tweeting in them). Our work will allow us to draw different conclusions from Twitter
data. By visualizing popularity and connectivity of tweets, we expect to be able to see popular users (most likely
celebrities), what they are talking about, what types of tweets are spawning large conversations, what hashtags are
popular, and where they originate. These are only a few examples of what is possible. Although we cannot predict exactly
what kind of insights can be provided by this new way of visualizing Twitter data, the above list provides a small example
of the kinds of things we expect our program to be able to provide to users.

We hope to see 3 very different types of tweets: tweets from celebrity figures, characterized by a large number of retweets
and replies; announcement and news tweets that are predominantly retweeted; and many much smaller threads of conversation
that consist of many interconnected \@reply tweets. 

\subsection{Environment}
\textbf{Characterize environment you intend to operate in. Does your project operate on Amazon Web Services? on the general Internet? in a data center?}

We intend to operate using Amazon Web Services. \sys consists of an always-on EC2 instance that is responsible for 
``listening'' to Twitter via Fabric and distilling the presentable information from it, a Hadoop cluster that caches 
results such that users can view the current live stream over a variable-range historical context (up to several weeks),
and a Web UI that allows users to view and interact with the data. The webpage will be hosted using GitHub pages (CITATION)
or simply on the EC2 machine; implementation details can be fleshed out on the fly. Visualizations could potentially
employ libraries/tools such as d3.js. 